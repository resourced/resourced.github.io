{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nResourceD is a complete monitoring and alerting solution for DevOps everywhere. It is an open source project with MIT license.\n\n\nComparison to (plenty of) other OSS solutions\n\n\n\n\n\n\nEasy to install. Just download the binaries, change the default config, and run. No \nyum install\n necessary.\n\n\n\n\n\n\nGood looking, easy to use, UI.\n\n\n\n\n\n\nIt comprises of only three components: Agent, Master, and PostgreSQL. That's it. Other solutions are often complex with a lot of components to manage.\n\n\n\n\n\n\nPostgreSQL is well understood and there are plenty of documentation on how to scale it and make it highly available.\n\n\n\n\n\n\nActive check is a first class citizen. Some other solutions provide only passive checks.\n\n\n\n\n\n\nThe agent offers a multiple of useful solutions under one binary, reducing the need of installing multiple daemons on every host.\n\n\n\n\n\n\nThe agent can proactively do things for you (based on boolean expressions on its data). Why alerts when it can solve its own problem?\n\n\n\n\n\n\nAgent Features\n\n\n\n\n\n\nIt gathers server data \n provides JSON endpoints for external programs to consume.\n\n\n\n\n\n\nIt provides 60+ native data collector in Go: dmidecode, docker, haproxy, mcrouter, memcache, mysql, nagios plugins, procfs, ps output, redis, varnish.\n\n\n\n\n\n\nIt tails log files and forward them to various locations. When forwarded to master, these loglines can then be used to create alerts.\n\n\n\n\n\n\nIt can receives Graphite or StatsD metrics and forward them to master. These metrics are useful for alerts.\n\n\n\n\n\n\nIt can be extended using scripting languages. \nExample Script\n \nExample Config Files\n\n\n\n\n\n\nIt can send passive checks directly from the host.\n\n\n\n\n\n\nIt can execute scripts based on boolean expressions on its data. \nExample\n\n\n\n\n\n\nIt is useful without the master, it can forward data to other services.\n\n\n\n\n\n\nMaster Features\n\n\n\n\n\n\nIt receives a lot of useful data from the agents: facts, metrics, and loglines.\n\n\n\n\n\n\nIt creates active checks based on any of these data.\n\n\n\n\n\n\nIt can also create active checks on ping, SSH, and HTTP.\n\n\n\n\n\n\nWhen running multiple masters, the check jobs are distributed equally among them. There's no single point of failure.\n\n\n\n\n\n\nIt provides you with SQL-like statements to query all of its data. \nExample\n\n\n\n\n\n\nIt allows you to view and search logs within time range.\n\n\n\n\n\n\nPrerequisite\n\n\n\n\nPostgresSQL 9.5.x or newer for Master.\n\n\n\n\nLinks\n\n\n\n\n\n\nAgent Repo\n\n\n\n\n\n\nAgent GoDoc\n\n\n\n\n\n\nMaster Repo\n\n\n\n\n\n\nMaster GoDoc", 
            "title": "Home"
        }, 
        {
            "location": "/#introduction", 
            "text": "ResourceD is a complete monitoring and alerting solution for DevOps everywhere. It is an open source project with MIT license.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#comparison-to-plenty-of-other-oss-solutions", 
            "text": "Easy to install. Just download the binaries, change the default config, and run. No  yum install  necessary.    Good looking, easy to use, UI.    It comprises of only three components: Agent, Master, and PostgreSQL. That's it. Other solutions are often complex with a lot of components to manage.    PostgreSQL is well understood and there are plenty of documentation on how to scale it and make it highly available.    Active check is a first class citizen. Some other solutions provide only passive checks.    The agent offers a multiple of useful solutions under one binary, reducing the need of installing multiple daemons on every host.    The agent can proactively do things for you (based on boolean expressions on its data). Why alerts when it can solve its own problem?", 
            "title": "Comparison to (plenty of) other OSS solutions"
        }, 
        {
            "location": "/#agent-features", 
            "text": "It gathers server data   provides JSON endpoints for external programs to consume.    It provides 60+ native data collector in Go: dmidecode, docker, haproxy, mcrouter, memcache, mysql, nagios plugins, procfs, ps output, redis, varnish.    It tails log files and forward them to various locations. When forwarded to master, these loglines can then be used to create alerts.    It can receives Graphite or StatsD metrics and forward them to master. These metrics are useful for alerts.    It can be extended using scripting languages.  Example Script   Example Config Files    It can send passive checks directly from the host.    It can execute scripts based on boolean expressions on its data.  Example    It is useful without the master, it can forward data to other services.", 
            "title": "Agent Features"
        }, 
        {
            "location": "/#master-features", 
            "text": "It receives a lot of useful data from the agents: facts, metrics, and loglines.    It creates active checks based on any of these data.    It can also create active checks on ping, SSH, and HTTP.    When running multiple masters, the check jobs are distributed equally among them. There's no single point of failure.    It provides you with SQL-like statements to query all of its data.  Example    It allows you to view and search logs within time range.", 
            "title": "Master Features"
        }, 
        {
            "location": "/#prerequisite", 
            "text": "PostgresSQL 9.5.x or newer for Master.", 
            "title": "Prerequisite"
        }, 
        {
            "location": "/#links", 
            "text": "Agent Repo    Agent GoDoc    Master Repo    Master GoDoc", 
            "title": "Links"
        }, 
        {
            "location": "/gallery/", 
            "text": "Signup Page\n\n\n\n\nAccess Token Management\n\n\n\n\nView Server Data\n\n\nAny numeric server data can be used to create graphs. Notice that you can query server data using SQL-like statement.\n\n\n\n\nGraphs Dashboard\n\n\n\n\nDashboard is responsive to any size screens. Graphs are draggable for sorting.\n\n\n\n\nLog Search\n\n\nUse SQL-like statement to search through your logs.\n\n\n\n\nChecks\n\n\nMinimize noise and maximize awareness by combining multiple checks with boolean expressions.\n\n\n\n\nCreate your own escalation policy.", 
            "title": "Gallery"
        }, 
        {
            "location": "/gallery/#signup-page", 
            "text": "", 
            "title": "Signup Page"
        }, 
        {
            "location": "/gallery/#access-token-management", 
            "text": "", 
            "title": "Access Token Management"
        }, 
        {
            "location": "/gallery/#view-server-data", 
            "text": "Any numeric server data can be used to create graphs. Notice that you can query server data using SQL-like statement.", 
            "title": "View Server Data"
        }, 
        {
            "location": "/gallery/#graphs-dashboard", 
            "text": "Dashboard is responsive to any size screens. Graphs are draggable for sorting.", 
            "title": "Graphs Dashboard"
        }, 
        {
            "location": "/gallery/#log-search", 
            "text": "Use SQL-like statement to search through your logs.", 
            "title": "Log Search"
        }, 
        {
            "location": "/gallery/#checks", 
            "text": "Minimize noise and maximize awareness by combining multiple checks with boolean expressions.   Create your own escalation policy.", 
            "title": "Checks"
        }, 
        {
            "location": "/installation-user-day-1/", 
            "text": "Install PostgreSQL 9.5.x or newer\n\n\nResourceD Master stores all its metadata and timeseries data on PostgreSQL 9.5.x or newer.\n\n\nThe minimum required version is 9.5 since we are using BRIN index for timeseries data. Other PostgreSQL features we use:\n\n\n\n\n\n\nJSONB column for various metadata.\n\n\n\n\n\n\nTable inheritance for timeseries data.\n\n\n\n\n\n\nFull text search for log search.\n\n\n\n\n\n\nGIN index for JSONB column.\n\n\n\n\n\n\nLISTEN/NOTIFY for pubsub between daemons.\n\n\n\n\n\n\nMany Databases\n\n\nWe encourage users to use multiple databases to separate concerns.\n\n\nThe core database should not share the same PostgreSQL as the timeseries databases.\n\n\nYou will see this reflected on the configuration files, each config file \nDSN\n can be configured to use a different database.\n\n\n# This example shows you how to create databases under resourced user. Feel free to use a different user.\n# Make sure user, password, and pg_hba.conf are configured correctly.\nsudo su - postgres\ncreateuser -P -e resourced\ncreatedb --owner=resourced resourced-master\ncreatedb --owner=resourced resourced-master-hosts\ncreatedb --owner=resourced resourced-master-ts-checks\ncreatedb --owner=resourced resourced-master-ts-events\ncreatedb --owner=resourced resourced-master-ts-executor-logs\ncreatedb --owner=resourced resourced-master-ts-logs\ncreatedb --owner=resourced resourced-master-ts-metrics\n\n\n\n\nCore\n\n\nThe core database is defined in \ngeneral.toml \n DSN\n.\n\n\nIt's usage pattern is read-heavy with the exception of \nhosts\n table.\n\n\nFor best performance, expand your \nshared_buffers\n so all your dataset is in RAM.\n\n\nThe master daemons communicate with each other via \nLISTEN/NOTIFY\n through core's database.\n\n\nThus, this is the recommended formula for \nmax_connections = \nnum-of-daemons\n + \nconnections-for-db-work\n\n\nMetrics\n\n\nThe metrics database stores all metrics timeseries data. It's configured in \nmetrics.toml \n DSN\n.\n\n\nMetrics timeseries data is partitioned daily. Each day has its own table. That means the heaviest write traffic will happen on today's date.\n\n\nLogs\n\n\nLogs database is another example of timeseries data. The forwarded log lines (from agents) are stored here.\n\n\nIt's configured in \nlogs.toml \n DSN\n.\n\n\nThis database is partitioned daily as well.\n\n\nChecks\n\n\nChecks database is also another form of timeseries database. It contains checks data for the purpose of alerting.\n\n\nIt's configured in \nchecks.toml \n DSN\n.\n\n\nThis database is partitioned daily as well.\n\n\nEvents\n\n\nEvents database is a user driven timeseries database. User can send arbitrary events to master daemons which then stores them here.\n\n\nIt's configured in \nevents.toml \n DSN\n.\n\n\nThis database is partitioned monthly.\n\n\nBy the end of day 1\n\n\nYou should expect to have completed:\n\n\n\n\n\n\nCreation of all the databases.\n\n\n\n\n\n\nCreation of all the PostgreSQL credentials for master daemon to use.\n\n\n\n\n\n\nThe configuration of \npg_hba.conf\n so master daemon hosts can access the databases.", 
            "title": "User Installation: Day 1"
        }, 
        {
            "location": "/installation-user-day-1/#install-postgresql-95x-or-newer", 
            "text": "ResourceD Master stores all its metadata and timeseries data on PostgreSQL 9.5.x or newer.  The minimum required version is 9.5 since we are using BRIN index for timeseries data. Other PostgreSQL features we use:    JSONB column for various metadata.    Table inheritance for timeseries data.    Full text search for log search.    GIN index for JSONB column.    LISTEN/NOTIFY for pubsub between daemons.", 
            "title": "Install PostgreSQL 9.5.x or newer"
        }, 
        {
            "location": "/installation-user-day-1/#many-databases", 
            "text": "We encourage users to use multiple databases to separate concerns.  The core database should not share the same PostgreSQL as the timeseries databases.  You will see this reflected on the configuration files, each config file  DSN  can be configured to use a different database.  # This example shows you how to create databases under resourced user. Feel free to use a different user.\n# Make sure user, password, and pg_hba.conf are configured correctly.\nsudo su - postgres\ncreateuser -P -e resourced\ncreatedb --owner=resourced resourced-master\ncreatedb --owner=resourced resourced-master-hosts\ncreatedb --owner=resourced resourced-master-ts-checks\ncreatedb --owner=resourced resourced-master-ts-events\ncreatedb --owner=resourced resourced-master-ts-executor-logs\ncreatedb --owner=resourced resourced-master-ts-logs\ncreatedb --owner=resourced resourced-master-ts-metrics", 
            "title": "Many Databases"
        }, 
        {
            "location": "/installation-user-day-1/#core", 
            "text": "The core database is defined in  general.toml   DSN .  It's usage pattern is read-heavy with the exception of  hosts  table.  For best performance, expand your  shared_buffers  so all your dataset is in RAM.  The master daemons communicate with each other via  LISTEN/NOTIFY  through core's database.  Thus, this is the recommended formula for  max_connections =  num-of-daemons  +  connections-for-db-work", 
            "title": "Core"
        }, 
        {
            "location": "/installation-user-day-1/#metrics", 
            "text": "The metrics database stores all metrics timeseries data. It's configured in  metrics.toml   DSN .  Metrics timeseries data is partitioned daily. Each day has its own table. That means the heaviest write traffic will happen on today's date.", 
            "title": "Metrics"
        }, 
        {
            "location": "/installation-user-day-1/#logs", 
            "text": "Logs database is another example of timeseries data. The forwarded log lines (from agents) are stored here.  It's configured in  logs.toml   DSN .  This database is partitioned daily as well.", 
            "title": "Logs"
        }, 
        {
            "location": "/installation-user-day-1/#checks", 
            "text": "Checks database is also another form of timeseries database. It contains checks data for the purpose of alerting.  It's configured in  checks.toml   DSN .  This database is partitioned daily as well.", 
            "title": "Checks"
        }, 
        {
            "location": "/installation-user-day-1/#events", 
            "text": "Events database is a user driven timeseries database. User can send arbitrary events to master daemons which then stores them here.  It's configured in  events.toml   DSN .  This database is partitioned monthly.", 
            "title": "Events"
        }, 
        {
            "location": "/installation-user-day-1/#by-the-end-of-day-1", 
            "text": "You should expect to have completed:    Creation of all the databases.    Creation of all the PostgreSQL credentials for master daemon to use.    The configuration of  pg_hba.conf  so master daemon hosts can access the databases.", 
            "title": "By the end of day 1"
        }, 
        {
            "location": "/installation-user-day-2/", 
            "text": "Master Installation \n Running\n\n\n\n\n\n\nDownload the tar.gz\n and unpack it. \n\n\n\n\n\n\nRun the database migration: \ncd path/to/resourced-master; resourced-master -c conf migrate up\n\n\n\n\n\n\nRun the server: \ncd path/to/resourced-master; resourced-master -c conf\n\n\n\n\n\n\nIt is highly recommended to daemonize the master using init/systemd/supervisord. You can follow the examples of init scripts \nhere\n\n\n\n\n\n\nThere is one option to set for running the master daemon. You can set it via \n-c\n flag or \nRESOURCED_MASTER_CONFIG_DIR\n environment variable. \ncd path/to/resourced-master; resourced-master -c config-files\n\n\nCreating New Migration Files\n\n\nResourceD timeseries databases are partitioned either monthly or daily.\n\n\nThe migration files are located here: \nmigrations/{core|ts-checks|ts-events|ts-executor-logs|ts-logs|ts-metrics}\n.\n\n\nWhen you looked inside those directories, you'll notice that only 2016 are provided.\n\n\nTo create new migration files, run \nscripts/migrations/{create|drop}-ts-{daily|events}.py\n. Each script contains comments on how to use it.\n\n\nAgent Reporting to Master\n\n\n\n\n\n\nCreate a new AccessToken using the GUI: Click \nyour@email.com\n drop down and select \nClusters\n menu option.\n\n\n\n\n\n\nNotice that there's an AccessToken created for you already. Copy it.\n\n\n\n\n\n\nPaste the value in the \nAccessToken\n section inside agent's \ngeneral.toml\n.\n\n\n\n\n\n\nRun the agent daemon:  \ncd path/to/resourced; RESOURCED_CONFIG_DIR=. resourced\n\n\n\n\n\n\nBy the end of day 2\n\n\nYou should expect to have:\n\n\n\n\n\n\nMaster daemon to be up and running and able to connect to all of the PostgreSQL databases.\n\n\n\n\n\n\nAgent is reporting data to master and you can see them in the UI.", 
            "title": "User Installation: Day 2"
        }, 
        {
            "location": "/installation-user-day-2/#master-installation-running", 
            "text": "Download the tar.gz  and unpack it.     Run the database migration:  cd path/to/resourced-master; resourced-master -c conf migrate up    Run the server:  cd path/to/resourced-master; resourced-master -c conf    It is highly recommended to daemonize the master using init/systemd/supervisord. You can follow the examples of init scripts  here    There is one option to set for running the master daemon. You can set it via  -c  flag or  RESOURCED_MASTER_CONFIG_DIR  environment variable.  cd path/to/resourced-master; resourced-master -c config-files", 
            "title": "Master Installation &amp; Running"
        }, 
        {
            "location": "/installation-user-day-2/#creating-new-migration-files", 
            "text": "ResourceD timeseries databases are partitioned either monthly or daily.  The migration files are located here:  migrations/{core|ts-checks|ts-events|ts-executor-logs|ts-logs|ts-metrics} .  When you looked inside those directories, you'll notice that only 2016 are provided.  To create new migration files, run  scripts/migrations/{create|drop}-ts-{daily|events}.py . Each script contains comments on how to use it.", 
            "title": "Creating New Migration Files"
        }, 
        {
            "location": "/installation-user-day-2/#agent-reporting-to-master", 
            "text": "Create a new AccessToken using the GUI: Click  your@email.com  drop down and select  Clusters  menu option.    Notice that there's an AccessToken created for you already. Copy it.    Paste the value in the  AccessToken  section inside agent's  general.toml .    Run the agent daemon:   cd path/to/resourced; RESOURCED_CONFIG_DIR=. resourced", 
            "title": "Agent Reporting to Master"
        }, 
        {
            "location": "/installation-user-day-2/#by-the-end-of-day-2", 
            "text": "You should expect to have:    Master daemon to be up and running and able to connect to all of the PostgreSQL databases.    Agent is reporting data to master and you can see them in the UI.", 
            "title": "By the end of day 2"
        }, 
        {
            "location": "/installation-user-day-3/", 
            "text": "Inviting Co-workers to the System\n\n\n\n\n\n\nUnder \nyour@email.com \n Clusters\n menu, click \nAdd User to Cluster\n button.\n\n\n\n\n\n\nEnter your co-worker email and give him/her the right permission.\n\n\n\n\n\n\nBy the end of day 3\n\n\n\n\nYour coworker should be able to login to the system and view your setup.", 
            "title": "User Installation: Day 3"
        }, 
        {
            "location": "/installation-user-day-3/#inviting-co-workers-to-the-system", 
            "text": "Under  your@email.com   Clusters  menu, click  Add User to Cluster  button.    Enter your co-worker email and give him/her the right permission.", 
            "title": "Inviting Co-workers to the System"
        }, 
        {
            "location": "/installation-user-day-3/#by-the-end-of-day-3", 
            "text": "Your coworker should be able to login to the system and view your setup.", 
            "title": "By the end of day 3"
        }, 
        {
            "location": "/installation-dev/", 
            "text": "(View this page if you are compiling from source)\n\n\nMaster Prerequisites\n\n\n1.\n Install PostgreSQL 9.5.x or newer\n\n\n2.\n Install Git\n\n\n3.\n Install Go 1.6.x or newer\n\n\nMaster Installation \n Running\n\n\n1.\n Create PostgreSQL databases\n\n\ncreatedb resourced-master\ncreatedb resourced-master-hosts\ncreatedb resourced-master-ts-checks\ncreatedb resourced-master-ts-events\ncreatedb resourced-master-ts-executor-logs\ncreatedb resourced-master-ts-logs\ncreatedb resourced-master-ts-metrics\n\n\n\n\n2.\n Get the source code.\n\n\ngo get github.com/resourced/resourced-master\n\n\n\n\n3.\n Run the PostgreSQL migration.\n\n\ncd $GOPATH/src/github.com/resourced/resourced-master\ngo run main.go -c tests/config-files migrate up\n\n# This is only for debugging and running tests during development\n# ./scripts/migrations/all.sh up\n\n\n\n\n4.\n Run the server\n\n\ncd $GOPATH/src/github.com/resourced/resourced-master\ngo run -c tests/config-files main.go\n\n\n\n\nMaster Configuration\n\n\nResourceD Master needs to know path to its configuration directory.\n\n\nYou can set it via \n-c\n flag or \nRESOURCED_MASTER_CONFIG_DIR\n environment variable.\n\n\nThe \n.tar.gz\n file provides you with a default config directory. In there, you will see the following files:\n\n\n\n\n\n\ngeneral.toml\n All default settings are defined in \ngeneral.toml\n.\n\n\n\n\n\n\nmetrics.toml\n All settings related to storing metrics data.\n\n\n\n\n\n\nevents.toml\n All settings related to storing events data.\n\n\n\n\n\n\nlogs.toml\n All settings related to storing logs data.\n\n\n\n\n\n\nchecks.toml\n All settings related to storing checks data.\n\n\n\n\n\n\nAgent Installation \n Running\n\n\n1.\n Get the source code.\n\n\ngo get github.com/resourced/resourced\n\n\n\n\n2.\n Run the server.\n\n\nRESOURCED_CONFIG_DIR=$GOPATH/src/github.com/resourced/resourced/tests/resourced-configs \\\ngo run $GOPATH/src/github.com/resourced/resourced/resourced.go\n\n\n\n\nAgent Reporting to Master\n\n\n1.\n Create a new AccessToken using the GUI: Click \nyour@email.com\n drop down and select \nClusters\n menu option.\n\n\n2.\n Notice that there's an AccessToken created for you already. Copy it.\n\n\n3.\n Paste the value in the \nAccessToken\n section inside \nresourced-configs/general.toml\n.", 
            "title": "Contributor Installation"
        }, 
        {
            "location": "/installation-dev/#master-prerequisites", 
            "text": "1.  Install PostgreSQL 9.5.x or newer  2.  Install Git  3.  Install Go 1.6.x or newer", 
            "title": "Master Prerequisites"
        }, 
        {
            "location": "/installation-dev/#master-installation-running", 
            "text": "1.  Create PostgreSQL databases  createdb resourced-master\ncreatedb resourced-master-hosts\ncreatedb resourced-master-ts-checks\ncreatedb resourced-master-ts-events\ncreatedb resourced-master-ts-executor-logs\ncreatedb resourced-master-ts-logs\ncreatedb resourced-master-ts-metrics  2.  Get the source code.  go get github.com/resourced/resourced-master  3.  Run the PostgreSQL migration.  cd $GOPATH/src/github.com/resourced/resourced-master\ngo run main.go -c tests/config-files migrate up\n\n# This is only for debugging and running tests during development\n# ./scripts/migrations/all.sh up  4.  Run the server  cd $GOPATH/src/github.com/resourced/resourced-master\ngo run -c tests/config-files main.go", 
            "title": "Master Installation &amp; Running"
        }, 
        {
            "location": "/installation-dev/#master-configuration", 
            "text": "ResourceD Master needs to know path to its configuration directory.  You can set it via  -c  flag or  RESOURCED_MASTER_CONFIG_DIR  environment variable.  The  .tar.gz  file provides you with a default config directory. In there, you will see the following files:    general.toml  All default settings are defined in  general.toml .    metrics.toml  All settings related to storing metrics data.    events.toml  All settings related to storing events data.    logs.toml  All settings related to storing logs data.    checks.toml  All settings related to storing checks data.", 
            "title": "Master Configuration"
        }, 
        {
            "location": "/installation-dev/#agent-installation-running", 
            "text": "1.  Get the source code.  go get github.com/resourced/resourced  2.  Run the server.  RESOURCED_CONFIG_DIR=$GOPATH/src/github.com/resourced/resourced/tests/resourced-configs \\\ngo run $GOPATH/src/github.com/resourced/resourced/resourced.go", 
            "title": "Agent Installation &amp; Running"
        }, 
        {
            "location": "/installation-dev/#agent-reporting-to-master", 
            "text": "1.  Create a new AccessToken using the GUI: Click  your@email.com  drop down and select  Clusters  menu option.  2.  Notice that there's an AccessToken created for you already. Copy it.  3.  Paste the value in the  AccessToken  section inside  resourced-configs/general.toml .", 
            "title": "Agent Reporting to Master"
        }, 
        {
            "location": "/installation-docs/", 
            "text": "(View this page if you are contributing to the documentation)\n\n\nPrerequisite\n\n\n\n\nInstall \nMkDocs\n: \npip install mkdocs\n\n\n\n\nContributing\n\n\n\n\n\n\ngit clone git@github.com:resourced/resourced.github.io.git\n\n\n\n\n\n\ncd path/to/resourced.github.io\n\n\n\n\n\n\nRun \nmkdocs serve\n to start a local server for viewing your changes.\n\n\n\n\n\n\nRun \nmkdocs build --clean\n to make sure every page is generated correctly.\n\n\n\n\n\n\nIf you are adding a new page, don't forget to update \nmkdocs.yml: pages:\n array.\n\n\n\n\n\n\nHow it works\n\n\n\n\n\n\nPlace or modify content under \ncontent-docs\n, the format is Markdown.\n\n\n\n\n\n\nThe local server will automatically detect your changes and update the HTML.", 
            "title": "Documantation Installation"
        }, 
        {
            "location": "/installation-docs/#prerequisite", 
            "text": "Install  MkDocs :  pip install mkdocs", 
            "title": "Prerequisite"
        }, 
        {
            "location": "/installation-docs/#contributing", 
            "text": "git clone git@github.com:resourced/resourced.github.io.git    cd path/to/resourced.github.io    Run  mkdocs serve  to start a local server for viewing your changes.    Run  mkdocs build --clean  to make sure every page is generated correctly.    If you are adding a new page, don't forget to update  mkdocs.yml: pages:  array.", 
            "title": "Contributing"
        }, 
        {
            "location": "/installation-docs/#how-it-works", 
            "text": "Place or modify content under  content-docs , the format is Markdown.    The local server will automatically detect your changes and update the HTML.", 
            "title": "How it works"
        }, 
        {
            "location": "/usage-agent-metrics-server/", 
            "text": "Collecting Server Metrics\n\n\nResourceD agent ships with more than 60 readers to help collect host data.\n\n\nMake sure you install ResourceD agent on every host and enable readers of your choice via \nreaders/*.toml\n config files.\n\n\nFeel free to take a look at \nthis link for help\n.\n\n\nUtilizing the Collected Server Data\n\n\nThe collected host data is incredibly useful for various purposes, for examples:\n\n\n\n\n\n\nCapistrano/Fabric can query which hosts have the lowest load average and only perform deployments there.\n\n\n\n\n\n\nYou can write plenty of custom Nagios scripts, querying the agent's endpoints, for alerting.\n\n\n\n\n\n\nYour database automatic failover scripts can be even more intelligent by consuming these host data.\n\n\n\n\n\n\nTo use these data curl the agent's HTTP endpoint. Example: \ncurl http://localhost:55555/paths\n.\n\n\nFrom there, you will see all the possible endpoints to read the data from.\n\n\nReporting Server Metrics to Master\n\n\nFor even greater power, configure the agents to report host data to master.\n\n\nThis is done by configuring \nwriters/resourced-master-host.toml\n config file. \nClick on this link for an example\n.\n\n\nOnce the master receive all hosts data, you can use the master's API endpoint for your scripting need.\n\n\nYou can also use the master's checks feature for all of your alerting needs.\n\n\nScaling beyond One Daemon\n\n\n(Skip this section if you don't have a huge traffic)\n\n\nIf you are sending so much HTTP traffic to the agent such that one instance is no longer enough,\n\n\nfeel free to run multiple agent instances running on different ports,\n\n\nand load balance them behind Nginx/HAProxy.", 
            "title": "Usage - Agent: Metrics: Server"
        }, 
        {
            "location": "/usage-agent-metrics-server/#collecting-server-metrics", 
            "text": "ResourceD agent ships with more than 60 readers to help collect host data.  Make sure you install ResourceD agent on every host and enable readers of your choice via  readers/*.toml  config files.  Feel free to take a look at  this link for help .", 
            "title": "Collecting Server Metrics"
        }, 
        {
            "location": "/usage-agent-metrics-server/#utilizing-the-collected-server-data", 
            "text": "The collected host data is incredibly useful for various purposes, for examples:    Capistrano/Fabric can query which hosts have the lowest load average and only perform deployments there.    You can write plenty of custom Nagios scripts, querying the agent's endpoints, for alerting.    Your database automatic failover scripts can be even more intelligent by consuming these host data.    To use these data curl the agent's HTTP endpoint. Example:  curl http://localhost:55555/paths .  From there, you will see all the possible endpoints to read the data from.", 
            "title": "Utilizing the Collected Server Data"
        }, 
        {
            "location": "/usage-agent-metrics-server/#reporting-server-metrics-to-master", 
            "text": "For even greater power, configure the agents to report host data to master.  This is done by configuring  writers/resourced-master-host.toml  config file.  Click on this link for an example .  Once the master receive all hosts data, you can use the master's API endpoint for your scripting need.  You can also use the master's checks feature for all of your alerting needs.", 
            "title": "Reporting Server Metrics to Master"
        }, 
        {
            "location": "/usage-agent-metrics-server/#scaling-beyond-one-daemon", 
            "text": "(Skip this section if you don't have a huge traffic)  If you are sending so much HTTP traffic to the agent such that one instance is no longer enough,  feel free to run multiple agent instances running on different ports,  and load balance them behind Nginx/HAProxy.", 
            "title": "Scaling beyond One Daemon"
        }, 
        {
            "location": "/usage-agent-metrics-live/", 
            "text": "Reporting Live Graphite or StatsD Metrics\n\n\nResourceD agent can be configured to listen on TCP and UDP port for receiving metrics.\n\n\nThe acceptable metrics format are:\n\n\n\n\n\n\nGraphite: \nprefix.key value unix-timestamp\n\n\n\n\n\n\nStatsD: \nprefix.key:value|g\n\n\n\n\n\n\nTo enable, make sure the following config block is configured correctly inside \ngeneral.toml\n:\n\n\n[MetricReceiver]\n# Metrics endpoints can receive both Graphite or StatsD payloads.\n# Send your custom metrics here.\n# The wire protocol are both TCP and UDP.\n# TLS files are only used for TCP connection.\nAddr = \n:55556\n\nCertFile = \n\nKeyFile = \n\n\n# 1. Every X interval, report agent's own stats to graphite endpoint.\n# 2. Every X interval, store StatsD data to in-memory storage.\nStatsInterval = \n60s\n\n\nHistogramReservoirSize = 1028\n\n\n\n\nTips\n\n\n\n\n\n\nIt's best to wrap the metrics sending code with error-swallowing try-catch because the application should not break when metrics reporting is disrupted.\n\n\n\n\n\n\nThere's no need to prefix metric key with hostname because ResourceD automatically tags every metric key with hostname as metadata.\n\n\n\n\n\n\nScaling beyond One Daemon\n\n\n(Skip this section if you don't have a huge traffic)\n\n\nIf you are sending so much metrics data to the agent such that one instance is no longer enough,\n\n\nfeel free to run multiple agent instances running on different ports,\n\n\nand load balance them behind Nginx/HAProxy.\n\n\n(Note: At this point you can only use the TCP endpoint.)", 
            "title": "Usage - Agent: Metrics: Live"
        }, 
        {
            "location": "/usage-agent-metrics-live/#reporting-live-graphite-or-statsd-metrics", 
            "text": "ResourceD agent can be configured to listen on TCP and UDP port for receiving metrics.  The acceptable metrics format are:    Graphite:  prefix.key value unix-timestamp    StatsD:  prefix.key:value|g    To enable, make sure the following config block is configured correctly inside  general.toml :  [MetricReceiver]\n# Metrics endpoints can receive both Graphite or StatsD payloads.\n# Send your custom metrics here.\n# The wire protocol are both TCP and UDP.\n# TLS files are only used for TCP connection.\nAddr =  :55556 \nCertFile =  \nKeyFile =  \n\n# 1. Every X interval, report agent's own stats to graphite endpoint.\n# 2. Every X interval, store StatsD data to in-memory storage.\nStatsInterval =  60s \n\nHistogramReservoirSize = 1028", 
            "title": "Reporting Live Graphite or StatsD Metrics"
        }, 
        {
            "location": "/usage-agent-metrics-live/#tips", 
            "text": "It's best to wrap the metrics sending code with error-swallowing try-catch because the application should not break when metrics reporting is disrupted.    There's no need to prefix metric key with hostname because ResourceD automatically tags every metric key with hostname as metadata.", 
            "title": "Tips"
        }, 
        {
            "location": "/usage-agent-metrics-live/#scaling-beyond-one-daemon", 
            "text": "(Skip this section if you don't have a huge traffic)  If you are sending so much metrics data to the agent such that one instance is no longer enough,  feel free to run multiple agent instances running on different ports,  and load balance them behind Nginx/HAProxy.  (Note: At this point you can only use the TCP endpoint.)", 
            "title": "Scaling beyond One Daemon"
        }, 
        {
            "location": "/usage-agent-application-general/", 
            "text": "Reporting Application Metrics\n\n\nFor application to report metrics, you need to install ResourceD agent on every application host.\n\n\nThen, the application can report metrics using Graphite/StatsD plain text protocol to the agent. The wire protocol uses TCP or UDP.\n\n\nTips\n\n\n\n\n\n\nIt's best to wrap the metrics sending code with error-swallowing try-catch because the application should not break when metrics reporting is disrupted.\n\n\n\n\n\n\nFeel free to log the error so it can still be shipped and analyzed by ResourceD.\n\n\n\n\n\n\nThere's no need to prefix metric key with hostname because ResourceD automatically tags every metric key with hostname as metadata.\n\n\n\n\n\n\nScaling beyond One Daemon\n\n\n(Skip this section if you don't have a huge traffic)\n\n\nIf you are sending so much metrics data to the agent such that one instance is no longer enough,\n\n\nfeel free to run multiple agent instances running on different ports,\n\n\nand load balance them behind Nginx/HAProxy.\n\n\n(Note: At this point you can only use the TCP endpoint.)", 
            "title": "Usage - Agent: Application: General"
        }, 
        {
            "location": "/usage-agent-application-general/#reporting-application-metrics", 
            "text": "For application to report metrics, you need to install ResourceD agent on every application host.  Then, the application can report metrics using Graphite/StatsD plain text protocol to the agent. The wire protocol uses TCP or UDP.", 
            "title": "Reporting Application Metrics"
        }, 
        {
            "location": "/usage-agent-application-general/#tips", 
            "text": "It's best to wrap the metrics sending code with error-swallowing try-catch because the application should not break when metrics reporting is disrupted.    Feel free to log the error so it can still be shipped and analyzed by ResourceD.    There's no need to prefix metric key with hostname because ResourceD automatically tags every metric key with hostname as metadata.", 
            "title": "Tips"
        }, 
        {
            "location": "/usage-agent-application-general/#scaling-beyond-one-daemon", 
            "text": "(Skip this section if you don't have a huge traffic)  If you are sending so much metrics data to the agent such that one instance is no longer enough,  feel free to run multiple agent instances running on different ports,  and load balance them behind Nginx/HAProxy.  (Note: At this point you can only use the TCP endpoint.)", 
            "title": "Scaling beyond One Daemon"
        }, 
        {
            "location": "/usage-agent-application-go/", 
            "text": "Reporting Go App Metrics\n\n\nWith the help of \ngithub.com/rcrowley/go-metrics\n, it is trivial to report application metrics to ResourceD.\n\n\nMake sure you install ResourceD agent on the application host, so it can send metrics data to the agent using TCP/UDP plain text graphite protocol.\n\n\nPrerequisite\n\n\n\n\ngo get github.com/rcrowley/go-metrics\n\n\n\n\nCollecting GC and Runtime Memory metrics\n\n\ngo-metrics\n provides user convenience functions to collect GC and Runtime Memory metrics.\n\n\nThe key is to report using Graphite format, take a look at the example below:\n\n\npackage main\n\nimport (\n    \ntime\n\n\n    \ngithub.com/Sirupsen/logrus\n\n    \ngithub.com/rcrowley/go-metrics\n\n    metrics_graphite \ngithub.com/cyberdelia/go-metrics-graphite\n\n)\n\nfunc main() {\n    // 1. Create a registry\n    // If you have other metrics to report, use the same registry.\n    r := metrics.NewRegistry()\n\n    metrics.RegisterDebugGCStats(r)\n    metrics.RegisterRuntimeMemStats(r)\n\n    // Collect every minute\n    go metrics.CaptureDebugGCStats(r, time.Second*60)\n    go metrics.CaptureRuntimeMemStats(r, time.Second*60)\n\n    // Publish metrics to graphite endpoint.\n    // Note that ResourceD agent is capable of receiving graphite metrics through TCP.\n    addr, err := net.ResolveTCPAddr(\ntcp\n, \n127.0.0.1:55556\n)\n    if err != nil {\n        logrus.Fatal(err)\n    }\n    go metrics_graphite.Graphite(r, time.Second*60, \nYourAppPrefix\n, addr)\n}\n\n\n\n\nYou can take a look at how Master daemon report its metrics for more examples:\n\n\n\n\n\n\nCreating a new registry with basic reporting.\n\n\n\n\n\n\nPublishing metrics to Graphite endpoint.", 
            "title": "Usage - Agent: Application: Go"
        }, 
        {
            "location": "/usage-agent-application-go/#reporting-go-app-metrics", 
            "text": "With the help of  github.com/rcrowley/go-metrics , it is trivial to report application metrics to ResourceD.  Make sure you install ResourceD agent on the application host, so it can send metrics data to the agent using TCP/UDP plain text graphite protocol.", 
            "title": "Reporting Go App Metrics"
        }, 
        {
            "location": "/usage-agent-application-go/#prerequisite", 
            "text": "go get github.com/rcrowley/go-metrics", 
            "title": "Prerequisite"
        }, 
        {
            "location": "/usage-agent-application-go/#collecting-gc-and-runtime-memory-metrics", 
            "text": "go-metrics  provides user convenience functions to collect GC and Runtime Memory metrics.  The key is to report using Graphite format, take a look at the example below:  package main\n\nimport (\n     time \n\n     github.com/Sirupsen/logrus \n     github.com/rcrowley/go-metrics \n    metrics_graphite  github.com/cyberdelia/go-metrics-graphite \n)\n\nfunc main() {\n    // 1. Create a registry\n    // If you have other metrics to report, use the same registry.\n    r := metrics.NewRegistry()\n\n    metrics.RegisterDebugGCStats(r)\n    metrics.RegisterRuntimeMemStats(r)\n\n    // Collect every minute\n    go metrics.CaptureDebugGCStats(r, time.Second*60)\n    go metrics.CaptureRuntimeMemStats(r, time.Second*60)\n\n    // Publish metrics to graphite endpoint.\n    // Note that ResourceD agent is capable of receiving graphite metrics through TCP.\n    addr, err := net.ResolveTCPAddr( tcp ,  127.0.0.1:55556 )\n    if err != nil {\n        logrus.Fatal(err)\n    }\n    go metrics_graphite.Graphite(r, time.Second*60,  YourAppPrefix , addr)\n}  You can take a look at how Master daemon report its metrics for more examples:    Creating a new registry with basic reporting.    Publishing metrics to Graphite endpoint.", 
            "title": "Collecting GC and Runtime Memory metrics"
        }, 
        {
            "location": "/usage-agent-logs-file/", 
            "text": "Collecting Log Lines from Files\n\n\nResourceD agent can be configured to collect log lines from files.\n\n\nMake sure you install ResourceD agent on every host and enable loggers of your choice via \nloggers/*.toml\n config files.\n\n\nFeel free to take a look at \nthis link for help\n.", 
            "title": "Usage - Agent: Logs: File"
        }, 
        {
            "location": "/usage-agent-logs-file/#collecting-log-lines-from-files", 
            "text": "ResourceD agent can be configured to collect log lines from files.  Make sure you install ResourceD agent on every host and enable loggers of your choice via  loggers/*.toml  config files.  Feel free to take a look at  this link for help .", 
            "title": "Collecting Log Lines from Files"
        }, 
        {
            "location": "/usage-agent-logs-live/", 
            "text": "Receiving Live Log Lines\n\n\nResourceD agent can be configured to listen on TCP and UDP port for receiving log lines.\n\n\nIt behave similarly to syslog listener. It can then forwards log lines to various targets.\n\n\n(Note: Log forwarding will be discuss in the next page)\n\n\nTo enable, make sure the following config block is configured correctly inside \ngeneral.toml\n:\n\n\n[LogReceiver]\n# Send your logs over TCP or UDP here.\n# TLS files are only used for TCP connection.\nAddr = \n:55557\n\nCertFile = \n\nKeyFile = \n\nWriteToMasterInterval = \n60s\n\n\n# To prevent memory leak, clean all logs when storage capacity reached N.\nAutoPruneLength = 10000\n\n\n\n\nProtocol\n\n\nThe protocol to ship logline is very simple:\n\n\n# Base64, useful when shipping multi line log.\ntype:base64|created:unix-timestamp|content:abc=\n\n# Plain\ntype:plain|created:unix-timestamp|content:abc\n\n\n\n\nTips\n\n\n\n\nIt's best to wrap the log sending code with error-swallowing try-catch because the application should not break when log sending is disrupted.\n\n\n\n\nScaling beyond One Daemon\n\n\n(Skip this section if you don't have a huge traffic)\n\n\nIf you are sending so much log data to the agent such that one instance is no longer enough,\n\n\nfeel free to run multiple agent instances running on different ports,\n\n\nand load balance them behind Nginx/HAProxy.\n\n\n(Note: At this point you can only use the TCP endpoint.)", 
            "title": "Usage - Agent: Logs: Live"
        }, 
        {
            "location": "/usage-agent-logs-live/#receiving-live-log-lines", 
            "text": "ResourceD agent can be configured to listen on TCP and UDP port for receiving log lines.  It behave similarly to syslog listener. It can then forwards log lines to various targets.  (Note: Log forwarding will be discuss in the next page)  To enable, make sure the following config block is configured correctly inside  general.toml :  [LogReceiver]\n# Send your logs over TCP or UDP here.\n# TLS files are only used for TCP connection.\nAddr =  :55557 \nCertFile =  \nKeyFile =  \nWriteToMasterInterval =  60s \n\n# To prevent memory leak, clean all logs when storage capacity reached N.\nAutoPruneLength = 10000", 
            "title": "Receiving Live Log Lines"
        }, 
        {
            "location": "/usage-agent-logs-live/#protocol", 
            "text": "The protocol to ship logline is very simple:  # Base64, useful when shipping multi line log.\ntype:base64|created:unix-timestamp|content:abc=\n\n# Plain\ntype:plain|created:unix-timestamp|content:abc", 
            "title": "Protocol"
        }, 
        {
            "location": "/usage-agent-logs-live/#tips", 
            "text": "It's best to wrap the log sending code with error-swallowing try-catch because the application should not break when log sending is disrupted.", 
            "title": "Tips"
        }, 
        {
            "location": "/usage-agent-logs-live/#scaling-beyond-one-daemon", 
            "text": "(Skip this section if you don't have a huge traffic)  If you are sending so much log data to the agent such that one instance is no longer enough,  feel free to run multiple agent instances running on different ports,  and load balance them behind Nginx/HAProxy.  (Note: At this point you can only use the TCP endpoint.)", 
            "title": "Scaling beyond One Daemon"
        }, 
        {
            "location": "/usage-agent-logs-forwarding/", 
            "text": "Forwarding to Multiple Targets\n\n\nResourceD agent can be configured to forward log lines to multiple targets:\n\n\n\n\n\n\nResourceD Master\n\n\n\n\n\n\nAnother Resourced Agent\n\n\n\n\n\n\nSyslog\n\n\n\n\n\n\nLocal File\n\n\n\n\n\n\nEach logger config file defines one source and multiple targets. Extensive examples are provided \nhere\n.\n\n\nThis feature inspiration comes from Apache Flume and Fluentd.", 
            "title": "Usage - Agent: Logs: Forwarding"
        }, 
        {
            "location": "/usage-agent-logs-forwarding/#forwarding-to-multiple-targets", 
            "text": "ResourceD agent can be configured to forward log lines to multiple targets:    ResourceD Master    Another Resourced Agent    Syslog    Local File    Each logger config file defines one source and multiple targets. Extensive examples are provided  here .  This feature inspiration comes from Apache Flume and Fluentd.", 
            "title": "Forwarding to Multiple Targets"
        }, 
        {
            "location": "/usage-master-hosts/", 
            "text": "Hosts Tab\n\n\nThis page shows you the latest information on all of your hosts.\n\n\nYou can think of it as facts/inventory database.\n\n\nWhat can you do with it?\n\n\n\n\n\n\nPrimarily, you can search information about your hosts based on various criteria:\n\n\n\n\n\n\nHostname\n\n\n\n\n\n\nHost tags\n\n\n\n\n\n\nArithmetic comparison on host data\n\n\n\n\n\n\n\n\n\n\nYou can then save your queries as bookmarks to come back later.\n\n\n\n\n\n\nEven better, use the \n/api/hosts?q=your-query\n API endpoint to aid your deployment strategies.\n\n\n\n\n\n\nQuery Language\n\n\nAs mentioned above, there are 3 fields to query host data on: hostname, tags, and JSON path.\n\n\nLimitation:\n You can only use \nAND\n conjunctive operators, for now.\n\n\nQuery by hostname\n\n\n\n\n\n\nExact match: \nhostname = \"localhost\"\n\n\n\n\n\n\nStarts-with match: \nhostname ~^ \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case insensitive: \nhostname ~* \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case sensitive: \nhostname ~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case sensitive: \nhostname !~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case insensitive: \nhostname !~* \"awesome-app-\"\n\n\n\n\n\n\nQuery by tags\n\n\n\n\n\n\nExact match: \ntags.mysql = 5.6.24\n\n\n\n\n\n\nMultiple exact match: \ntags.mysql = 5.6.24 and tags.redis = 3.0.1\n\n\n\n\n\n\nQuery by JSON path\n\n\nInternally, all of host data are stored as JSON documents.\n\n\nTo make an arithmetic comparison of a single attribute, start with the prefix path and then use \n.\n delimited separator as you get deeper into the JSON structure.\n\n\nThe UI flattens the nested structure for you so that you can visually identify all of the attributes easily.\n\n\nExamples:\n\n\n\n\n\n\n/free.Swap.Used \n 10000000\n\n\n\n\n\n\n/uptime.LoadAvg1m \n 10", 
            "title": "Usage - Master: Hosts"
        }, 
        {
            "location": "/usage-master-hosts/#hosts-tab", 
            "text": "This page shows you the latest information on all of your hosts.  You can think of it as facts/inventory database.", 
            "title": "Hosts Tab"
        }, 
        {
            "location": "/usage-master-hosts/#what-can-you-do-with-it", 
            "text": "Primarily, you can search information about your hosts based on various criteria:    Hostname    Host tags    Arithmetic comparison on host data      You can then save your queries as bookmarks to come back later.    Even better, use the  /api/hosts?q=your-query  API endpoint to aid your deployment strategies.", 
            "title": "What can you do with it?"
        }, 
        {
            "location": "/usage-master-hosts/#query-language", 
            "text": "As mentioned above, there are 3 fields to query host data on: hostname, tags, and JSON path.  Limitation:  You can only use  AND  conjunctive operators, for now.  Query by hostname    Exact match:  hostname = \"localhost\"    Starts-with match:  hostname ~^ \"awesome-app-\"    Regex match, case insensitive:  hostname ~* \"awesome-app-\"    Regex match, case sensitive:  hostname ~ \"awesome-app-\"    Regex match negation, case sensitive:  hostname !~ \"awesome-app-\"    Regex match negation, case insensitive:  hostname !~* \"awesome-app-\"    Query by tags    Exact match:  tags.mysql = 5.6.24    Multiple exact match:  tags.mysql = 5.6.24 and tags.redis = 3.0.1    Query by JSON path  Internally, all of host data are stored as JSON documents.  To make an arithmetic comparison of a single attribute, start with the prefix path and then use  .  delimited separator as you get deeper into the JSON structure.  The UI flattens the nested structure for you so that you can visually identify all of the attributes easily.  Examples:    /free.Swap.Used   10000000    /uptime.LoadAvg1m   10", 
            "title": "Query Language"
        }, 
        {
            "location": "/usage-master-graphs/", 
            "text": "Graphs Tab\n\n\nThis page allows you to create dashboard full of line charts.\n\n\nUnlike a lot of existing systems out there, ResourceD does not automatically chart every single host metric.\n\n\nInstead, the UI allows you to pick which metric to charts.\n\n\nHow to chart a host metric?\n\n\nGo to \nHosts\n tab and look for \nChart Metric?\n button. Press it and the master daemon will start charting metric.\n\n\nHow to create a dashboard with multiple charts?\n\n\n\n\n\n\nGo to \nGraphs\n tab and click \nNew Graph\n button. This will create a new dashboard with zero charts.\n\n\n\n\n\n\nThen click the \nview\n button next to your newly created dashboard. It will take you to a new page.\n\n\n\n\n\n\nclick \nAdd Charts\n button to populate your dashboard with charts.", 
            "title": "Usage - Master: Graphs"
        }, 
        {
            "location": "/usage-master-graphs/#graphs-tab", 
            "text": "This page allows you to create dashboard full of line charts.  Unlike a lot of existing systems out there, ResourceD does not automatically chart every single host metric.  Instead, the UI allows you to pick which metric to charts.", 
            "title": "Graphs Tab"
        }, 
        {
            "location": "/usage-master-graphs/#how-to-chart-a-host-metric", 
            "text": "Go to  Hosts  tab and look for  Chart Metric?  button. Press it and the master daemon will start charting metric.", 
            "title": "How to chart a host metric?"
        }, 
        {
            "location": "/usage-master-graphs/#how-to-create-a-dashboard-with-multiple-charts", 
            "text": "Go to  Graphs  tab and click  New Graph  button. This will create a new dashboard with zero charts.    Then click the  view  button next to your newly created dashboard. It will take you to a new page.    click  Add Charts  button to populate your dashboard with charts.", 
            "title": "How to create a dashboard with multiple charts?"
        }, 
        {
            "location": "/usage-master-logs/", 
            "text": "Logs Tab\n\n\nThis page shows you the latest information on all of your logs.\n\n\nWhat can you do with it?\n\n\n\n\n\n\nPrimarily, you can search information about your logs based on various criteria:\n\n\n\n\n\n\nDate time range (from \n to).\n\n\n\n\n\n\nHostname\n\n\n\n\n\n\nHost tags\n\n\n\n\n\n\nFull text search on loglines.\n\n\n\n\n\n\n\n\n\n\nYou can then save your queries as bookmarks to come back later.\n\n\n\n\n\n\nThe \n/api/logs?q=your-query\nfrom=unix-timestamp\nto=unix-timestamp\n API endpoint is provided as well.\n\n\n\n\n\n\nQuery Language\n\n\nAs mentioned above, there are 3 fields to query host data on: hostname, tags, and full text search on loglines.\n\n\nLimitation:\n You can only use \nAND\n conjunctive operators, for now.\n\n\nQuery by hostname\n\n\n\n\n\n\nExact match: \nhostname = \"localhost\"\n\n\n\n\n\n\nStarts-with match: \nhostname ~^ \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case insensitive: \nhostname ~* \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case sensitive: \nhostname ~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case sensitive: \nhostname !~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case insensitive: \nhostname !~* \"awesome-app-\"\n\n\n\n\n\n\nQuery by tags\n\n\n\n\n\n\nExact match: \ntags.mysql = 5.6.24\n\n\n\n\n\n\nMultiple exact match: \ntags.mysql = 5.6.24 and tags.redis = 3.0.1\n\n\n\n\n\n\nQuery by logline full text search\n\n\n\n\n\n\nWord per word tokens:\n \nlogline search \"error \n mysql\"\n. The search query must consist of single tokens separated by the Boolean operators \n (AND), | (OR) and ! (NOT). These operators can be grouped using parentheses. See \nthis link\n for more details.\n\n\n\n\n\n\nFree-form text search:\n \nlogline search \"my free form text search\"\n.\n\n\n\n\n\n\nCombo(Advanced) search:\n \nlogline search 'com.apple.periodic-monthly | mysqld | WindowServer || my free form text search'\n. The \n||\n and \n have higher precedence and they allow users to combine both techniques together.", 
            "title": "Usage - Master: Logs"
        }, 
        {
            "location": "/usage-master-logs/#logs-tab", 
            "text": "This page shows you the latest information on all of your logs.", 
            "title": "Logs Tab"
        }, 
        {
            "location": "/usage-master-logs/#what-can-you-do-with-it", 
            "text": "Primarily, you can search information about your logs based on various criteria:    Date time range (from   to).    Hostname    Host tags    Full text search on loglines.      You can then save your queries as bookmarks to come back later.    The  /api/logs?q=your-query from=unix-timestamp to=unix-timestamp  API endpoint is provided as well.", 
            "title": "What can you do with it?"
        }, 
        {
            "location": "/usage-master-logs/#query-language", 
            "text": "As mentioned above, there are 3 fields to query host data on: hostname, tags, and full text search on loglines.  Limitation:  You can only use  AND  conjunctive operators, for now.  Query by hostname    Exact match:  hostname = \"localhost\"    Starts-with match:  hostname ~^ \"awesome-app-\"    Regex match, case insensitive:  hostname ~* \"awesome-app-\"    Regex match, case sensitive:  hostname ~ \"awesome-app-\"    Regex match negation, case sensitive:  hostname !~ \"awesome-app-\"    Regex match negation, case insensitive:  hostname !~* \"awesome-app-\"    Query by tags    Exact match:  tags.mysql = 5.6.24    Multiple exact match:  tags.mysql = 5.6.24 and tags.redis = 3.0.1    Query by logline full text search    Word per word tokens:   logline search \"error   mysql\" . The search query must consist of single tokens separated by the Boolean operators   (AND), | (OR) and ! (NOT). These operators can be grouped using parentheses. See  this link  for more details.    Free-form text search:   logline search \"my free form text search\" .    Combo(Advanced) search:   logline search 'com.apple.periodic-monthly | mysqld | WindowServer || my free form text search' . The  ||  and   have higher precedence and they allow users to combine both techniques together.", 
            "title": "Query Language"
        }, 
        {
            "location": "/usage-master-checks/", 
            "text": "Checks Tab\n\n\nThis page allows you to create and manage alerts.\n\n\nEach check go through a list of hosts and make decision based on check expressions.\n\n\nHow to create a new check?\n\n\nClick the \nNew Check\n button. It will ask you to fill in a form.\n\n\n\n\n\n\nName:\n The name of your check.\n\n\n\n\n\n\nInterval:\n How frequently the master daemon will re-check.\n\n\n\n\n\n\nQuery for Hosts:\n Remember the \nHosts\n tab? It allows you to query list of hosts dynamically. You can use the same query statement here to fetch the list of hosts to check.\n\n\n\n\n\n\nIf you want to have a static list of hosts, fill in the text area instead.\n\n\n\n\n\n\nCheck Expressions:\n This is the real meat of the check system. See the subsection below.\n\n\n\n\n\n\nWhat is Check Expression?\n\n\nCheck expression allows user to be very specific when defining alert criteria.\n\n\nEach expression perform check on a \ngroup of hosts\n and raise alert when at minimum \nN\n hosts are affected.\n\n\nThe purpose of this feature is to minimize noise. For example: often times, it is ok for a system to have one dead host out of twenty.\n\n\nThere are 7 different types of check: \n(Note: You can only check charted metrics)\n\n\n\n\n\n\nRaw host data:\n This type should be familiar to Nagios users, it checks the current, absolute value of a particular metric.\n\n\n\n\n\n\nRelative host data:\n Often times, absolute value checks are not enough. If you need to check changes-over-time, this check is for you.\n\n\n\n\n\n\nLog data:\n Use this check if you need to check the count of loglines. Remember the \nLogs\n tab? You can use the same query statement to count loglines.\n\n\n\n\n\n\nPing, SSH, HTTP/S:\n These are active checks \n(check the hosts directly)\n to make sure hosts are truly well-behaving.\n\n\n\n\n\n\nMultiple Check Expressions Under One Check?\n\n\nYou can have multiple expressions by pressing \n+\n button. The purpose of this feature is to minimize noise \n(We all know how frustrating it is to receive false alerts)\n.\n\n\nThe more specific your check is, the less noisy it is. You can use \nAND\n or \nOR\n for combining expressions.\n\n\nWhat is a trigger?\n\n\nOnce a check is created, it doesn't actually do anything for you yet. To have a meaningful, actionable alerts, you need to create triggers.\n\n\nThere are 4 different kind of triggers:\n\n\n\n\n\n\nDo Nothing\n\n\n\n\n\n\nSend Email\n\n\n\n\n\n\nSend SMS\n\n\n\n\n\n\nSend PagerDuty\n\n\n\n\n\n\nCan I create Pager Escalation Rules?\n\n\nA la PagerDuty?\n\n\nYes. The nifty thing about triggers is that you can create multiple of them for one check.\n\n\nTo create an escalation policy, just stack multiple triggers. For example:\n\n\n\n\n\n\nBetween 1-3 violations, do nothing.\n\n\n\n\n\n\nBetween 4-6 violations, email tier1@example.com\n\n\n\n\n\n\nBetween 7-10 violations, email tier2@example.com\n\n\n\n\n\n\nBetween 11-20 violations, email svp@example.com", 
            "title": "Usage - Master: Checks"
        }, 
        {
            "location": "/usage-master-checks/#checks-tab", 
            "text": "This page allows you to create and manage alerts.  Each check go through a list of hosts and make decision based on check expressions.", 
            "title": "Checks Tab"
        }, 
        {
            "location": "/usage-master-checks/#how-to-create-a-new-check", 
            "text": "Click the  New Check  button. It will ask you to fill in a form.    Name:  The name of your check.    Interval:  How frequently the master daemon will re-check.    Query for Hosts:  Remember the  Hosts  tab? It allows you to query list of hosts dynamically. You can use the same query statement here to fetch the list of hosts to check.    If you want to have a static list of hosts, fill in the text area instead.    Check Expressions:  This is the real meat of the check system. See the subsection below.", 
            "title": "How to create a new check?"
        }, 
        {
            "location": "/usage-master-checks/#what-is-check-expression", 
            "text": "Check expression allows user to be very specific when defining alert criteria.  Each expression perform check on a  group of hosts  and raise alert when at minimum  N  hosts are affected.  The purpose of this feature is to minimize noise. For example: often times, it is ok for a system to have one dead host out of twenty.  There are 7 different types of check:  (Note: You can only check charted metrics)    Raw host data:  This type should be familiar to Nagios users, it checks the current, absolute value of a particular metric.    Relative host data:  Often times, absolute value checks are not enough. If you need to check changes-over-time, this check is for you.    Log data:  Use this check if you need to check the count of loglines. Remember the  Logs  tab? You can use the same query statement to count loglines.    Ping, SSH, HTTP/S:  These are active checks  (check the hosts directly)  to make sure hosts are truly well-behaving.", 
            "title": "What is Check Expression?"
        }, 
        {
            "location": "/usage-master-checks/#multiple-check-expressions-under-one-check", 
            "text": "You can have multiple expressions by pressing  +  button. The purpose of this feature is to minimize noise  (We all know how frustrating it is to receive false alerts) .  The more specific your check is, the less noisy it is. You can use  AND  or  OR  for combining expressions.", 
            "title": "Multiple Check Expressions Under One Check?"
        }, 
        {
            "location": "/usage-master-checks/#what-is-a-trigger", 
            "text": "Once a check is created, it doesn't actually do anything for you yet. To have a meaningful, actionable alerts, you need to create triggers.  There are 4 different kind of triggers:    Do Nothing    Send Email    Send SMS    Send PagerDuty", 
            "title": "What is a trigger?"
        }, 
        {
            "location": "/usage-master-checks/#can-i-create-pager-escalation-rules", 
            "text": "A la PagerDuty?  Yes. The nifty thing about triggers is that you can create multiple of them for one check.  To create an escalation policy, just stack multiple triggers. For example:    Between 1-3 violations, do nothing.    Between 4-6 violations, email tier1@example.com    Between 7-10 violations, email tier2@example.com    Between 11-20 violations, email svp@example.com", 
            "title": "Can I create Pager Escalation Rules?"
        }, 
        {
            "location": "/api-master-authentication/", 
            "text": "Every HTTP request requires AccessToken passed as basic auth user. Users can create a new AccessToken from inside the web application: \nyou@example.com \n Clusters\n menu.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/hosts')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/hosts', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/hosts", 
            "title": "API Doc - Master: Auth"
        }, 
        {
            "location": "/api-master-hosts-get/", 
            "text": "GET http://localhost:55655/api/hosts\n\n\nGet all hosts data.\n\n\nQuery Parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nq\n\n\n''\n\n\nString\n\n\nAllows user to filter hosts data using SQL-like statement.\n\n\n\n\n\n\n\n\nQuery Language\n\n\nThere are 3 fields to query host data on: hostname, tags, and JSON path.\n\n\nLimitation:\n You can only use \nAND\n conjunctive operators, for now.\n\n\nQuery by hostname\n\n\n\n\n\n\nExact match: \nhostname = \"localhost\"\n\n\n\n\n\n\nStarts-with match: \nhostname ~^ \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case insensitive: \nhostname ~* \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case sensitive: \nhostname ~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case sensitive: \nhostname !~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case insensitive: \nhostname !~* \"awesome-app-\"\n\n\n\n\n\n\nQuery by tags\n\n\n\n\n\n\nExact match: \ntags.mysql = 5.6.24\n\n\n\n\n\n\nMultiple exact match: \ntags.mysql = 5.6.24 and tags.redis = 3.0.1\n\n\n\n\n\n\nQuery by JSON path\n\n\nTo craft JSON path query, start with ResourceD path and then use \".\" delimited separator as you get deeper into the JSON structure.\n\n\nFor example, let's say your resourced agent shipped \n/free\n data: \n{\"/free\": {\"Swap\": {\"Free\": 0, \"Used\": 0, \"Total\": 0}, \"Memory\": {\"Free\": 1346609152}}}\n\n\nYou can then query \nSwap -\n Used\n this way: \n/free.Swap.Used \n 10000000\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/hosts')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/hosts', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/hosts\n\n\n\n\nReturn Payload\n\n\n[\n  {\n    \nClusterID\n: \u200b1,\n    \nHostname\n: \nmy-mac-mini.local\n,\n    \nUpdated\n: \n2016-05-15T23:47:01.441652Z\n,\n    \nTags\n: {\n      \nos\n: \nOS X Yosemite\n,\n      \npostgres\n: \n9.4.2\n,\n      \nredis\n: \n3.0.1\n,\n      \nrole\n: \nhome-dev\n\n    },\n    \nData\n: {\n      \n/free\n: {\n        \nSwap\n: {\n            \nFree\n: \u200b1770520576,\n            \nUsed\n: \u200b376963072,\n            \nTotal\n: \u200b2147483648,\n            \nFreeGB\n: \u200b1,\n            \nFreeMB\n: \u200b1770,\n            \nUsedGB\n: \u200b0,\n            \nUsedMB\n: \u200b376,\n            \nTotalGB\n: \u200b2,\n            \nTotalMB\n: \u200b2147,\n            \nFreePercent\n: \u200b82\n        },\n        \nMemory\n: {\n          \nFree\n: \u200b685666304,\n          \nUsed\n: \u200b7904268288,\n          \nTotal\n: \u200b8589934592,\n          \nFreeGB\n: \u200b0,\n          \nFreeMB\n: \u200b685,\n          \nUsedGB\n: \u200b7,\n          \nUsedMB\n: \u200b7904,\n          \nTotalGB\n: \u200b8,\n          \nTotalMB\n: \u200b8589,\n          \nActualFree\n: \u200b3156926464,\n          \nActualUsed\n: \u200b5433008128,\n          \nFreePercent\n: \u200b7,\n          \nUsedPercent\n: \u200b92,\n          \nActualFreeGB\n: \u200b3,\n          \nActualFreeMB\n: \u200b3156,\n          \nActualUsedGB\n: \u200b5,\n          \nActualUsedMB\n: \u200b5433,\n          \nActualFreePercent\n: \u200b36,\n          \nActualUsedPercent\n: \u200b63\n        }\n      },\n      \n/uptime\n: {\n        \nUptime\n: \n24 days, 16:55\n,\n        \nTimeZone\n: \nPDT\n,\n        \nLoadAvg1m\n: \u200b1.6044921875,\n        \nLoadAvg5m\n: \u200b2.099609375,\n        \nLoadAvg15m\n: \u200b2.072265625,\n        \nCurrentTime\n: \n16:46:58\n,\n        \nCurrentTimeUnixNano\n: \u200b1463356018787249200\n      }\n    }\n  },\n  {\n    \nClusterID\n: \u200b1,\n    \nHostname\n: \nmy-mac-pro.local\n,\n    \nUpdated\n: \n2016-05-15T23:47:01.441652Z\n,\n    \nTags\n: {\n      \nos\n: \nOS X Yosemite\n,\n      \npostgres\n: \n9.5.1\n,\n      \nredis\n: \n3.0.1\n,\n      \nrole\n: \nhome-dev\n\n    },\n    \nData\n: {\n      \ntruncated\n: \n...\n\n    }\n  }\n]", 
            "title": "API Doc - Master: GET /api/hosts"
        }, 
        {
            "location": "/api-master-hosts-get/#query-parameters", 
            "text": "Parameter  Default  Type  Description      q  ''  String  Allows user to filter hosts data using SQL-like statement.", 
            "title": "Query Parameters"
        }, 
        {
            "location": "/api-master-hosts-get/#query-language", 
            "text": "There are 3 fields to query host data on: hostname, tags, and JSON path.  Limitation:  You can only use  AND  conjunctive operators, for now.  Query by hostname    Exact match:  hostname = \"localhost\"    Starts-with match:  hostname ~^ \"awesome-app-\"    Regex match, case insensitive:  hostname ~* \"awesome-app-\"    Regex match, case sensitive:  hostname ~ \"awesome-app-\"    Regex match negation, case sensitive:  hostname !~ \"awesome-app-\"    Regex match negation, case insensitive:  hostname !~* \"awesome-app-\"    Query by tags    Exact match:  tags.mysql = 5.6.24    Multiple exact match:  tags.mysql = 5.6.24 and tags.redis = 3.0.1    Query by JSON path  To craft JSON path query, start with ResourceD path and then use \".\" delimited separator as you get deeper into the JSON structure.  For example, let's say your resourced agent shipped  /free  data:  {\"/free\": {\"Swap\": {\"Free\": 0, \"Used\": 0, \"Total\": 0}, \"Memory\": {\"Free\": 1346609152}}}  You can then query  Swap -  Used  this way:  /free.Swap.Used   10000000  # Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/hosts')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =  uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend  # Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/hosts', auth=HTTPBasicAuth('accesstoken', ''))  # cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/hosts", 
            "title": "Query Language"
        }, 
        {
            "location": "/api-master-hosts-get/#return-payload", 
            "text": "[\n  {\n     ClusterID : \u200b1,\n     Hostname :  my-mac-mini.local ,\n     Updated :  2016-05-15T23:47:01.441652Z ,\n     Tags : {\n       os :  OS X Yosemite ,\n       postgres :  9.4.2 ,\n       redis :  3.0.1 ,\n       role :  home-dev \n    },\n     Data : {\n       /free : {\n         Swap : {\n             Free : \u200b1770520576,\n             Used : \u200b376963072,\n             Total : \u200b2147483648,\n             FreeGB : \u200b1,\n             FreeMB : \u200b1770,\n             UsedGB : \u200b0,\n             UsedMB : \u200b376,\n             TotalGB : \u200b2,\n             TotalMB : \u200b2147,\n             FreePercent : \u200b82\n        },\n         Memory : {\n           Free : \u200b685666304,\n           Used : \u200b7904268288,\n           Total : \u200b8589934592,\n           FreeGB : \u200b0,\n           FreeMB : \u200b685,\n           UsedGB : \u200b7,\n           UsedMB : \u200b7904,\n           TotalGB : \u200b8,\n           TotalMB : \u200b8589,\n           ActualFree : \u200b3156926464,\n           ActualUsed : \u200b5433008128,\n           FreePercent : \u200b7,\n           UsedPercent : \u200b92,\n           ActualFreeGB : \u200b3,\n           ActualFreeMB : \u200b3156,\n           ActualUsedGB : \u200b5,\n           ActualUsedMB : \u200b5433,\n           ActualFreePercent : \u200b36,\n           ActualUsedPercent : \u200b63\n        }\n      },\n       /uptime : {\n         Uptime :  24 days, 16:55 ,\n         TimeZone :  PDT ,\n         LoadAvg1m : \u200b1.6044921875,\n         LoadAvg5m : \u200b2.099609375,\n         LoadAvg15m : \u200b2.072265625,\n         CurrentTime :  16:46:58 ,\n         CurrentTimeUnixNano : \u200b1463356018787249200\n      }\n    }\n  },\n  {\n     ClusterID : \u200b1,\n     Hostname :  my-mac-pro.local ,\n     Updated :  2016-05-15T23:47:01.441652Z ,\n     Tags : {\n       os :  OS X Yosemite ,\n       postgres :  9.5.1 ,\n       redis :  3.0.1 ,\n       role :  home-dev \n    },\n     Data : {\n       truncated :  ... \n    }\n  }\n]", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metrics-get/", 
            "text": "GET http://localhost:55655/api/metrics/{id:[0-9]+}\n\n\nGet all metrics data by id.\n\n\nQuery Parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfrom\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\nto\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1?from=1463551343\nto=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1?from=1463551343\nto=1463551643', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1?from=1463551343\nto=1463551643'\n\n\n\n\nReturn Payload\n\n\n[\n   {\n      \nname\n:\nlocalhost.local\n,\n      \ndata\n:[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "API Doc - Master: GET /api/metrics/{id:[0-9]+}"
        }, 
        {
            "location": "/api-master-metrics-get/#query-parameters", 
            "text": "Parameter  Default  Type  Description      from  ''  UNIX epoch  Allows user to provide a time range.    to  ''  UNIX epoch  Allows user to provide a time range.     # Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1?from=1463551343 to=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =  uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend  # Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1?from=1463551343 to=1463551643', auth=HTTPBasicAuth('accesstoken', ''))  # cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1?from=1463551343 to=1463551643'", 
            "title": "Query Parameters"
        }, 
        {
            "location": "/api-master-metrics-get/#return-payload", 
            "text": "[\n   {\n       name : localhost.local ,\n       data :[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metrics-15m-get/", 
            "text": "GET http://localhost:55655/api/metrics/{id:[0-9]+}/15m\n\n\nGet all metrics data by id aggregate per 15 minutes.\n\n\nQuery Parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfrom\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\nto\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\naggr\n\n\n'avg'\n\n\nstring\n\n\nAllows user to choose between avg, max, min, or sum.\n\n\n\n\n\n\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1/15m?from=1463551343\nto=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1/15m?from=1463551343\nto=1463551643', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1/15m?from=1463551343\nto=1463551643'\n\n\n\n\nReturn Payload\n\n\n[\n   {\n      \nname\n:\nlocalhost.local\n,\n      \ndata\n:[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "API Doc - Master: GET /api/metrics/{id:[0-9]+}/15m"
        }, 
        {
            "location": "/api-master-metrics-15m-get/#query-parameters", 
            "text": "Parameter  Default  Type  Description      from  ''  UNIX epoch  Allows user to provide a time range.    to  ''  UNIX epoch  Allows user to provide a time range.    aggr  'avg'  string  Allows user to choose between avg, max, min, or sum.     # Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1/15m?from=1463551343 to=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =  uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend  # Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1/15m?from=1463551343 to=1463551643', auth=HTTPBasicAuth('accesstoken', ''))  # cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1/15m?from=1463551343 to=1463551643'", 
            "title": "Query Parameters"
        }, 
        {
            "location": "/api-master-metrics-15m-get/#return-payload", 
            "text": "[\n   {\n       name : localhost.local ,\n       data :[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metrics-host-get/", 
            "text": "GET http://localhost:55655/api/metrics/{id:[0-9]+}/hosts/{host}\n\n\nGet all metrics data by id.\n\n\nQuery Parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfrom\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\nto\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1/hosts/localhost?from=1463551343\nto=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1/hosts/localhost?from=1463551343\nto=1463551643', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1/hosts/localhost?from=1463551343\nto=1463551643'\n\n\n\n\nReturn Payload\n\n\n[\n   {\n      \nname\n:\nlocalhost\n,\n      \ndata\n:[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "API Doc - Master: GET /api/metrics/{id:[0-9]+}/hosts/{host}"
        }, 
        {
            "location": "/api-master-metrics-host-get/#query-parameters", 
            "text": "Parameter  Default  Type  Description      from  ''  UNIX epoch  Allows user to provide a time range.    to  ''  UNIX epoch  Allows user to provide a time range.     # Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1/hosts/localhost?from=1463551343 to=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =  uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend  # Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1/hosts/localhost?from=1463551343 to=1463551643', auth=HTTPBasicAuth('accesstoken', ''))  # cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1/hosts/localhost?from=1463551343 to=1463551643'", 
            "title": "Query Parameters"
        }, 
        {
            "location": "/api-master-metrics-host-get/#return-payload", 
            "text": "[\n   {\n       name : localhost ,\n       data :[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metrics-host-15m-get/", 
            "text": "GET http://localhost:55655/api/metrics/{id:[0-9]+}/hosts/{host}/15m\n\n\nGet all metrics data by id aggregate per 15 minutes.\n\n\nQuery Parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfrom\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\nto\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\naggr\n\n\n''\n\n\nstring\n\n\nAllows user to choose between avg, max, min, or sum. If nothing is defined, then all four will be returned.\n\n\n\n\n\n\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1/hosts/localhost/15m?from=1463551343\nto=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1/hosts/localhost/15m?from=1463551343\nto=1463551643', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1/hosts/localhost/15m?from=1463551343\nto=1463551643'\n\n\n\n\nReturn Payload\n\n\n[\n   {\n      \nname\n:\nlocalhost\n,\n      \ndata\n:[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "API Doc - Master: GET /api/metrics/{id:[0-9]+}/hosts/{host}/15m"
        }, 
        {
            "location": "/api-master-metrics-host-15m-get/#query-parameters", 
            "text": "Parameter  Default  Type  Description      from  ''  UNIX epoch  Allows user to provide a time range.    to  ''  UNIX epoch  Allows user to provide a time range.    aggr  ''  string  Allows user to choose between avg, max, min, or sum. If nothing is defined, then all four will be returned.     # Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metrics/1/hosts/localhost/15m?from=1463551343 to=1463551643')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =  uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend  # Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metrics/1/hosts/localhost/15m?from=1463551343 to=1463551643', auth=HTTPBasicAuth('accesstoken', ''))  # cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: 'http://localhost:55655/api/metrics/1/hosts/localhost/15m?from=1463551343 to=1463551643'", 
            "title": "Query Parameters"
        }, 
        {
            "location": "/api-master-metrics-host-15m-get/#return-payload", 
            "text": "[\n   {\n       name : localhost ,\n       data :[\n         [\n            1463551368452,\n            2.4794921875\n         ],\n         [\n            1463551398426,\n            2.08056640625\n         ],\n         [\n            1463551428441,\n            1.76806640625\n         ],\n         [\n            1463551458452,\n            1.78466796875\n         ],\n         [\n            1463551488466,\n            1.7685546875\n         ],\n         [\n            1463551518507,\n            1.56787109375\n         ],\n         [\n            1463551548526,\n            1.6630859375\n         ],\n         [\n            1463551578536,\n            1.56005859375\n         ],\n         [\n            1463551608543,\n            1.40283203125\n         ],\n         [\n            1463551638565,\n            1.3271484375\n         ]\n      ]\n   }\n]", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-events-post/", 
            "text": "POST http://localhost:55655/api/events\n\n\nSubmit an event object.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/events')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n    request = Net::HTTP::Post.new(uri.request_uri, initheader = {'Content-Type' =\n'application/json'})\n    request.basic_auth 'accesstoken', ''\n    request.body = '{\nfrom\n: 1463551343, \nto\n: 1463551643, \ndescription\n: \nDeployed app server\n}'\n\n    response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.post(\n    'http://localhost:55655/api/events',\n    auth=HTTPBasicAuth('accesstoken', ''),\n    body={\nfrom\n: 1463551343, \nto\n: 1463551643, \ndescription\n: \nDeployed app server\n}\n)\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: -X POST \\\n    -H \nAccept: application/json\n \\\n    -H \nContent-Type: application/json\n \\\n    -d '{\nfrom\n: 1463551343, \nto\n: 1463551643, \ndescription\n: \nDeployed app server\n}' \\\n    'http://localhost:55655/api/events'\n\n\n\n\nSend Payload\n\n\n{\n    \nfrom\n: 1463551343,\n    \nto\n: 1463551643,\n    \ndescription\n: \nDeployed app server\n\n}\n\n\n\n\nReturn Payload\n\n\n{\n    \nID\n: 1,\n    \nClusterID\n: 1,\n    \nCreatedFrom\n: 1463551343,\n    \nCreatedTo\n: 1463551643,\n    \nDescription\n: \nDeployed app server\n\n}", 
            "title": "API Doc - Master: POST /api/events"
        }, 
        {
            "location": "/api-master-events-post/#send-payload", 
            "text": "{\n     from : 1463551343,\n     to : 1463551643,\n     description :  Deployed app server \n}", 
            "title": "Send Payload"
        }, 
        {
            "location": "/api-master-events-post/#return-payload", 
            "text": "{\n     ID : 1,\n     ClusterID : 1,\n     CreatedFrom : 1463551343,\n     CreatedTo : 1463551643,\n     Description :  Deployed app server \n}", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-events-delete/", 
            "text": "DELETE http://localhost:55655/api/events/{id:[0-9]+}\n\n\nDelete an event object by id.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/events/1')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n    request = Net::HTTP::Delete.new(uri.request_uri, initheader = {'Content-Type' =\n'application/json'})\n    request.basic_auth 'accesstoken', ''\n\n    response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.delete('http://localhost:55655/api/events/1', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: -X DELETE 'http://localhost:55655/api/events/1'\n\n\n\n\nSend Payload\n\n\n{\n    \nfrom\n: 1463551343,\n    \nto\n: 1463551643,\n    \ndescription\n: \nDeployed app server\n\n}\n\n\n\n\nReturn Payload\n\n\n{\n    \nID\n: 1,\n    \nMessage\n: \nDeleted event\n\n}", 
            "title": "API Doc - Master: DELETE /api/events/{id:[0-9]+}"
        }, 
        {
            "location": "/api-master-events-delete/#send-payload", 
            "text": "{\n     from : 1463551343,\n     to : 1463551643,\n     description :  Deployed app server \n}", 
            "title": "Send Payload"
        }, 
        {
            "location": "/api-master-events-delete/#return-payload", 
            "text": "{\n     ID : 1,\n     Message :  Deleted event \n}", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-logs-post/", 
            "text": "POST http://localhost:55655/api/logs\n\n\nSubmit loglines.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/logs')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n    request = Net::HTTP::Post.new(uri.request_uri, initheader = {'Content-Type' =\n'application/json'})\n    request.basic_auth 'accesstoken', ''\n    request.body = '{\nHost\n: {\nName\n: \nlocalhost\n,\nTags\n: {\nrole\n: \napp-server\n}}, \nData\n: {\nLoglines\n: [{\nCreated\n: unix-timestamp, \nContent\n: \nmultiple loglines in an array\n}], \nFilename\n: \nfull path to filename where the logs came from\n}}'\n\n    response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.post(\n    'http://localhost:55655/api/logs',\n    auth=HTTPBasicAuth('accesstoken', ''),\n    body={\n        \nHost\n: {\n            \nName\n: \nlocalhost\n,\n            \nTags\n: {\n                \nrole\n: \napp-server\n\n            }\n        },\n        \nData\n: {\n            \nLoglines\n: [\n                {\nCreated\n: unix-timestamp, \nContent\n: \nmultiple loglines in an array\n}\n            ],\n            \nFilename\n: \nfull path to filename where the logs came from\n\n        }\n    }\n)\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: -X POST \\\n    -H \nAccept: application/json\n \\\n    -H \nContent-Type: application/json\n \\\n    -d '{\nHost\n: {\nName\n: \nlocalhost\n,\nTags\n: {\nrole\n: \napp-server\n}}, \nData\n: {\nLoglines\n: [{\nCreated\n: unix-timestamp, \nContent\n: \nmultiple loglines in an array\n}], \nFilename\n: \nfull path to filename where the logs came from\n}}' \\\n    'http://localhost:55655/api/logs'\n\n\n\n\nSend Payload\n\n\n{\n    \nHost\n: {\n        \nName\n: \nlocalhost\n,\n        \nTags\n: {\n            \nrole\n: \napp-server\n\n        }\n    },\n    \nData\n: {\n        \nLoglines\n: [{\nCreated\n: unix-timestamp, \nContent\n: \nmultiple loglines in an array\n}],\n        \nFilename\n: \nfull path to filename where the logs came from\n\n    }\n}\n\n\n\n\nReturn Payload\n\n\n{\n    \nMessage\n: \nSuccess\n\n}", 
            "title": "API Doc - Master: POST /api/logs"
        }, 
        {
            "location": "/api-master-logs-post/#send-payload", 
            "text": "{\n     Host : {\n         Name :  localhost ,\n         Tags : {\n             role :  app-server \n        }\n    },\n     Data : {\n         Loglines : [{ Created : unix-timestamp,  Content :  multiple loglines in an array }],\n         Filename :  full path to filename where the logs came from \n    }\n}", 
            "title": "Send Payload"
        }, 
        {
            "location": "/api-master-logs-post/#return-payload", 
            "text": "{\n     Message :  Success \n}", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-logs-get/", 
            "text": "GET http://localhost:55655/api/logs\n\n\nGet all logs data.\n\n\nQuery Parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDefault\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfrom\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\nto\n\n\n''\n\n\nUNIX epoch\n\n\nAllows user to provide a time range.\n\n\n\n\n\n\nq\n\n\n''\n\n\nString\n\n\nAllows user to filter logs data using SQL-like statement.\n\n\n\n\n\n\n\n\nQuery Language\n\n\nThere are 3 fields to query host data on: hostname, tags, and logline search.\n\n\nLimitation:\n You can only use \nAND\n conjunctive operators, for now.\n\n\nQuery by hostname\n\n\n\n\n\n\nExact match: \nhostname = \"localhost\"\n\n\n\n\n\n\nStarts-with match: \nhostname ~^ \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case insensitive: \nhostname ~* \"awesome-app-\"\n\n\n\n\n\n\nRegex match, case sensitive: \nhostname ~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case sensitive: \nhostname !~ \"awesome-app-\"\n\n\n\n\n\n\nRegex match negation, case insensitive: \nhostname !~* \"awesome-app-\"\n\n\n\n\n\n\nQuery by tags\n\n\n\n\n\n\nExact match: \ntags.mysql = 5.6.24\n\n\n\n\n\n\nMultiple exact match: \ntags.mysql = 5.6.24 and tags.redis = 3.0.1\n\n\n\n\n\n\nQuery by logline\n\n\nResourceD offers full-text search for loglines. Basic example: \nlogline search \"error \n mysql\"\n.\n\n\nThe search query must consist of single tokens separated by the Boolean operators \n (AND), | (OR) and ! (NOT). These operators can be grouped using parentheses.\n\n\nVisit http://www.postgresql.org/docs/current/static/textsearch-controls.html for more details.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/logs')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/logs', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/logs\n\n\n\n\nReturn Payload\n\n\n[\n  {\n    \nClusterID\n: \u200b1,\n    \nHostname\n: \nlocalhost\n,\n    \nCreated\n: \n2016-05-15T23:47:01.441652Z\n,\n    \nTags\n: {\n      \nos\n: \nOS X Yosemite\n,\n      \npostgres\n: \n9.4.2\n,\n      \nredis\n: \n3.0.1\n,\n      \nrole\n: \nhome-dev\n\n    },\n    \nFilename\n: \n,\n    \nLogline\n: \nfoo log\n\n  },\n  {\n    \nClusterID\n: \u200b1,\n    \nHostname\n: \nlocalhost\n,\n    \nCreated\n: \n2016-05-15T23:47:01.441652Z\n,\n    \nTags\n: {\n      \nos\n: \nOS X Yosemite\n,\n      \npostgres\n: \n9.4.2\n,\n      \nredis\n: \n3.0.1\n,\n      \nrole\n: \nhome-dev\n\n    },\n    \nFilename\n: \n,\n    \nLogline\n: \nbar log\n\n  }\n]", 
            "title": "API Doc - Master: GET /api/logs"
        }, 
        {
            "location": "/api-master-logs-get/#query-parameters", 
            "text": "Parameter  Default  Type  Description      from  ''  UNIX epoch  Allows user to provide a time range.    to  ''  UNIX epoch  Allows user to provide a time range.    q  ''  String  Allows user to filter logs data using SQL-like statement.", 
            "title": "Query Parameters"
        }, 
        {
            "location": "/api-master-logs-get/#query-language", 
            "text": "There are 3 fields to query host data on: hostname, tags, and logline search.  Limitation:  You can only use  AND  conjunctive operators, for now.  Query by hostname    Exact match:  hostname = \"localhost\"    Starts-with match:  hostname ~^ \"awesome-app-\"    Regex match, case insensitive:  hostname ~* \"awesome-app-\"    Regex match, case sensitive:  hostname ~ \"awesome-app-\"    Regex match negation, case sensitive:  hostname !~ \"awesome-app-\"    Regex match negation, case insensitive:  hostname !~* \"awesome-app-\"    Query by tags    Exact match:  tags.mysql = 5.6.24    Multiple exact match:  tags.mysql = 5.6.24 and tags.redis = 3.0.1    Query by logline  ResourceD offers full-text search for loglines. Basic example:  logline search \"error   mysql\" .  The search query must consist of single tokens separated by the Boolean operators   (AND), | (OR) and ! (NOT). These operators can be grouped using parentheses.  Visit http://www.postgresql.org/docs/current/static/textsearch-controls.html for more details.  # Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/logs')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =  uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend  # Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/logs', auth=HTTPBasicAuth('accesstoken', ''))  # cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/logs", 
            "title": "Query Language"
        }, 
        {
            "location": "/api-master-logs-get/#return-payload", 
            "text": "[\n  {\n     ClusterID : \u200b1,\n     Hostname :  localhost ,\n     Created :  2016-05-15T23:47:01.441652Z ,\n     Tags : {\n       os :  OS X Yosemite ,\n       postgres :  9.4.2 ,\n       redis :  3.0.1 ,\n       role :  home-dev \n    },\n     Filename :  ,\n     Logline :  foo log \n  },\n  {\n     ClusterID : \u200b1,\n     Hostname :  localhost ,\n     Created :  2016-05-15T23:47:01.441652Z ,\n     Tags : {\n       os :  OS X Yosemite ,\n       postgres :  9.4.2 ,\n       redis :  3.0.1 ,\n       role :  home-dev \n    },\n     Filename :  ,\n     Logline :  bar log \n  }\n]", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metadata-post/", 
            "text": "POST http://localhost:55655/api/metadata/{key}\n\n\nSubmit a metadata object.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metadata/foo/bar')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n    request = Net::HTTP::Post.new(uri.request_uri, initheader = {'Content-Type' =\n'application/json'})\n    request.basic_auth 'accesstoken', ''\n    request.body = '{\nsome\n: \ndata\n, \ndescription\n: \nuseful during server orchestration\n}'\n\n    response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.post(\n    'http://localhost:55655/api/metadata/foo/bar',\n    auth=HTTPBasicAuth('accesstoken', ''),\n    body={\nsome\n: \ndata\n, \ndescription\n: \nuseful during server orchestration\n}\n)\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: -X POST \\\n    -H \nAccept: application/json\n \\\n    -H \nContent-Type: application/json\n \\\n    -d '{\nsome\n: \ndata\n, \ndescription\n: \nuseful during server orchestration\n}' \\\n    'http://localhost:55655/api/metadata/foo/bar'\n\n\n\n\nSend Payload\n\n\n{\n    \nsome\n: \ndata\n,\n    \ndescription\n: \nuseful during server orchestration\n\n}\n\n\n\n\nReturn Payload\n\n\n{\n    \nClusterID\n: 1,\n    \nKey\n: \nfoo/bar\n,\n    \nData\n: {\n        \nsome\n: \ndata\n,\n        \ndescription\n: \nuseful during server orchestration\n\n    }\n}", 
            "title": "API Doc - Master: POST /api/metadata/{key}"
        }, 
        {
            "location": "/api-master-metadata-post/#send-payload", 
            "text": "{\n     some :  data ,\n     description :  useful during server orchestration \n}", 
            "title": "Send Payload"
        }, 
        {
            "location": "/api-master-metadata-post/#return-payload", 
            "text": "{\n     ClusterID : 1,\n     Key :  foo/bar ,\n     Data : {\n         some :  data ,\n         description :  useful during server orchestration \n    }\n}", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metadata-delete/", 
            "text": "DELETE http://localhost:55655/api/metadata/{key}\n\n\nDelete an metadata object by key.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metadata/foo/bar')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n    request = Net::HTTP::Delete.new(uri.request_uri, initheader = {'Content-Type' =\n'application/json'})\n    request.basic_auth 'accesstoken', ''\n\n    response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.delete('http://localhost:55655/api/metadata/1', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: -X DELETE 'http://localhost:55655/api/metadata/foo/bar'\n\n\n\n\nReturn Payload\n\n\n{\n    \nClusterID\n: 1,\n    \nKey\n: \nfoo/bar\n,\n    \nData\n: {\n        \nsome\n: \ndata\n,\n        \ndescription\n: \nuseful during server orchestration\n\n    }\n}", 
            "title": "API Doc - Master: DELETE /api/metadata/{key}"
        }, 
        {
            "location": "/api-master-metadata-delete/#return-payload", 
            "text": "{\n     ClusterID : 1,\n     Key :  foo/bar ,\n     Data : {\n         some :  data ,\n         description :  useful during server orchestration \n    }\n}", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metadata-get/", 
            "text": "GET http://localhost:55655/api/metadata/{key}\n\n\nGet metadata by key.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metadata/foo/bar')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metadata/foo/bar', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/metadata/foo/bar\n\n\n\n\nReturn Payload\n\n\n{\n    \nClusterID\n: 1,\n    \nKey\n: \nfoo/bar\n,\n    \nData\n: {\n        \nsome\n: \ndata\n,\n        \ndescription\n: \nuseful during server orchestration\n\n    }\n}", 
            "title": "API Doc - Master: GET /api/metadata/{key}"
        }, 
        {
            "location": "/api-master-metadata-get/#return-payload", 
            "text": "{\n     ClusterID : 1,\n     Key :  foo/bar ,\n     Data : {\n         some :  data ,\n         description :  useful during server orchestration \n    }\n}", 
            "title": "Return Payload"
        }, 
        {
            "location": "/api-master-metadata-all/", 
            "text": "GET http://localhost:55655/api/metadata\n\n\nGet all metadata.\n\n\n# Ruby example\nrequire 'net/http'\nrequire 'net/https'\n\nuri = URI('http://localhost:55655/api/metadata')\n\nNet::HTTP.start(uri.host, uri.port, :use_ssl =\n uri.scheme == 'https') do |http|\n  request = Net::HTTP::Get.new uri.request_uri\n  request.basic_auth 'accesstoken', ''\n\n  response = http.request request\nend\n\n\n\n\n# Python example\n# Requests is a 3rd party library\nfrom requests.auth import HTTPBasicAuth\nresponse = requests.get('http://localhost:55655/api/metadata', auth=HTTPBasicAuth('accesstoken', ''))\n\n\n\n\n# cURL example\n# Notice the double colon at the end of Access Token.\ncurl -u accesstoken: http://localhost:55655/api/metadata\n\n\n\n\nReturn Payload\n\n\n[\n    {\n        \nClusterID\n: 1,\n        \nKey\n: \nfoo/bar\n,\n        \nData\n: {\n            \nsome\n: \ndata\n,\n            \ndescription\n: \nuseful during server orchestration\n\n        }\n    },\n    {\n        \nClusterID\n: 1,\n        \nKey\n: \nfoo/bar/baz\n,\n        \nData\n: {\n            \nsome\n: \ndata\n,\n            \ndescription\n: \nuseful during server orchestration\n\n        }\n    }\n]", 
            "title": "API Doc - Master: GET /api/metadata"
        }, 
        {
            "location": "/api-master-metadata-all/#return-payload", 
            "text": "[\n    {\n         ClusterID : 1,\n         Key :  foo/bar ,\n         Data : {\n             some :  data ,\n             description :  useful during server orchestration \n        }\n    },\n    {\n         ClusterID : 1,\n         Key :  foo/bar/baz ,\n         Data : {\n             some :  data ,\n             description :  useful during server orchestration \n        }\n    }\n]", 
            "title": "Return Payload"
        }
    ]
}